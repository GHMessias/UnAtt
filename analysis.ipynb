{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List, Callable, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# --- Configurações principais ---\n",
    "CATEGORY_ORDER = [\"Super_Weak\", \"Weakest\", \"Weak\", \"Strong\", \"Strongest\"]  # ordem dos eixos no radar\n",
    "PATH_COL_CANDIDATES = [\"path\", \"filepath\", \"file\", 0]  # tentativas de nome/posição para a primeira coluna\n",
    "\n",
    "\n",
    "def _ensure_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Garante que o DataFrame tenha nomes de colunas adequados.\n",
    "    A 1ª coluna (sem nome) vira 'path' se necessário.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Se a primeira coluna não tiver nome ou for numérica (0), renomeia para 'path'\n",
    "    if df.columns[0] not in df.columns or df.columns[0] == 0:\n",
    "        # Caso já tenha sido lido com header=None, defina colunas manualmente\n",
    "        if len(df.columns) >= 9 and (isinstance(df.columns[0], int) or str(df.columns[0]).startswith(\"Unnamed\")):\n",
    "            df.columns = [\"path\", \"Strongest\", \"Strong\", \"Weak\", \"Weakest\", \"Super_Weak\",\n",
    "                          \"median_alpha\", \"n\", \"median_ntail\"]\n",
    "        else:\n",
    "            # Se já veio com nomes, apenas garanta que a primeira seja 'path'\n",
    "            cols = list(df.columns)\n",
    "            cols[0] = \"path\"\n",
    "            df.columns = cols\n",
    "    else:\n",
    "        # Se a primeira já tem nome, ainda assim tente padronizar para 'path' se for algo próximo\n",
    "        if df.columns[0] not in [\"path\"]:\n",
    "            cols = list(df.columns)\n",
    "            cols[0] = \"path\"\n",
    "            df.columns = cols\n",
    "    return df\n",
    "\n",
    "\n",
    "def _coerce_bool01(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converte colunas booleanas/strings 'True'/'False' para 0/1.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Coluna esperada não encontrada: {c}\")\n",
    "        # Converte strings 'True'/'False' para boolean\n",
    "        if df[c].dtype == object:\n",
    "            df[c] = df[c].astype(str).str.strip().str.lower().map({\"true\": True, \"false\": False})\n",
    "        # Converte boolean para int\n",
    "        if df[c].dtype == bool or df[c].dropna().isin([True, False]).all():\n",
    "            df[c] = df[c].astype(\"float\").astype(\"Int64\").fillna(0).astype(int)\n",
    "        # Se ainda for numérica, mantenha\n",
    "        if not np.issubdtype(df[c].dtype, np.number):\n",
    "            # Último recurso: tente converter direto\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def default_class_extractor(path_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai a 'classe' a partir do final do path do .gml.\n",
    "    Exemplos:\n",
    "      ..._3.gml          -> '3'\n",
    "      ..._complete.gml   -> 'complete'\n",
    "      ..._class_A.gml    -> 'A'  (pega o trecho entre '_' final e '.gml')\n",
    "    \"\"\"\n",
    "    name = Path(path_str).name\n",
    "    m = re.search(r\"_([^_/]+)\\.gml$\", name)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    # fallback: se não encontrou, use o nome do arquivo sem extensão\n",
    "    return Path(path_str).stem\n",
    "\n",
    "\n",
    "def _prepare_long_table(\n",
    "    dfs: List[pd.DataFrame],\n",
    "    labels: Optional[List[str]] = None,\n",
    "    class_extractor: Callable[[str], str] = default_class_extractor,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Concatena os dataframes, adiciona a coluna 'source' (rótulo do DF de origem),\n",
    "    extrai a 'class' do path, e retorna uma tabela longa pronta para agrupar por classe.\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = [f\"DF_{i+1}\" for i in range(len(dfs))]\n",
    "    assert len(labels) == len(dfs), \"labels deve ter o mesmo tamanho de dfs\"\n",
    "\n",
    "    normed = []\n",
    "    for df, label in zip(dfs, labels):\n",
    "        df = _ensure_columns(df)\n",
    "        df = _coerce_bool01(df, [\"Strongest\", \"Strong\", \"Weak\", \"Weakest\", \"Super_Weak\"])\n",
    "        if \"path\" not in df.columns:\n",
    "            raise ValueError(\"A primeira coluna deve conter o caminho do .gml e ser chamada de 'path'.\")\n",
    "        df = df.copy()\n",
    "        df[\"class\"] = df[\"path\"].astype(str).apply(class_extractor)\n",
    "        df[\"source\"] = label\n",
    "        normed.append(df[[\"path\", \"class\", \"source\"] + CATEGORY_ORDER])\n",
    "\n",
    "    long_df = pd.concat(normed, ignore_index=True)\n",
    "    return long_df\n",
    "\n",
    "\n",
    "def plot_radars_per_class(\n",
    "    dfs: List[pd.DataFrame],\n",
    "    labels: Optional[List[str]] = None,\n",
    "    class_extractor: Callable[[str], str] = default_class_extractor,\n",
    "    aggregate: str = \"mean\",  # 'mean' | 'sum' | 'first'\n",
    "    figsize: tuple = (6, 6),\n",
    "    tight_layout: bool = True,\n",
    "    save_dir: Optional[Path] = None,\n",
    "    show: bool = True,\n",
    ") -> Dict[str, Path]:\n",
    "    \"\"\"\n",
    "    Cria um radar chart por classe, sobrepondo um polígono por DataFrame (source).\n",
    "    Retorna um dicionário {classe: caminho_png} se save_dir for fornecido.\n",
    "    \"\"\"\n",
    "    long_df = _prepare_long_table(dfs, labels, class_extractor)\n",
    "\n",
    "    # Se houver mais de uma linha por (class, source), agregue\n",
    "    if aggregate == \"mean\":\n",
    "        agg_df = long_df.groupby([\"class\", \"source\"], as_index=False)[CATEGORY_ORDER].mean()\n",
    "    elif aggregate == \"sum\":\n",
    "        agg_df = long_df.groupby([\"class\", \"source\"], as_index=False)[CATEGORY_ORDER].sum()\n",
    "    elif aggregate == \"first\":\n",
    "        agg_df = long_df.groupby([\"class\", \"source\"], as_index=False)[CATEGORY_ORDER].first()\n",
    "    else:\n",
    "        raise ValueError(\"aggregate deve ser 'mean', 'sum' ou 'first'.\")\n",
    "\n",
    "    classes = sorted(agg_df[\"class\"].unique(), key=lambda x: (str(x) != \"complete\", x))\n",
    "    n_axes = len(CATEGORY_ORDER)\n",
    "    angles = np.linspace(0, 2 * math.pi, n_axes, endpoint=False).tolist()\n",
    "\n",
    "    saved_paths = {}\n",
    "\n",
    "    for cls in classes:\n",
    "        sub = agg_df[agg_df[\"class\"] == cls].sort_values(\"source\")\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # Preparar figura\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111, polar=True)\n",
    "\n",
    "        # eixos\n",
    "        ax.set_xticks(angles)\n",
    "        ax.set_xticklabels(CATEGORY_ORDER)\n",
    "        ax.set_ylim(0, 1)  # como são 0/1, limite em [0,1]; se usar somas/médias além de 1, ajuste aqui.\n",
    "\n",
    "        # plotar cada fonte\n",
    "        for _, row in sub.iterrows():\n",
    "            values = row[CATEGORY_ORDER].to_numpy(dtype=float)\n",
    "            # fechar o polígono\n",
    "            values = np.concatenate([values, values[:1]])\n",
    "            angs = angles + angles[:1]\n",
    "            ax.plot(angs, values, linewidth=2, label=row[\"source\"])\n",
    "            ax.fill(angs, values, alpha=0.10)\n",
    "\n",
    "        ax.set_title(f\"Scale-Free Profile — Classe: {cls}\", va=\"bottom\")\n",
    "        ax.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1.05))\n",
    "\n",
    "        if tight_layout:\n",
    "            plt.tight_layout()\n",
    "\n",
    "        # salvar se solicitado\n",
    "        if save_dir is not None:\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "            out_path = save_dir / f\"radar_class_{cls}.png\"\n",
    "            fig.savefig(out_path, dpi=200)\n",
    "            saved_paths[str(cls)] = out_path\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close(fig)\n",
    "\n",
    "    return saved_paths\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# EXEMPLO DE USO\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemplo: lendo um CSV no formato mostrado (sem header)\n",
    "    # Se você já tem os DataFrames prontos, pule esta parte e passe diretamente em dfs=[...]\n",
    "    csv_text = \"\"\"datasets/GenCAT/AttributedGraphDataset:BlogCatalog_n_0_m_0/gmls/AttributedGraphDataset:BlogCatalog_0.gml,False,False,False,False,False,3.150000000000002,897,261.0\n",
    "datasets/GenCAT/AttributedGraphDataset:BlogCatalog_n_0_m_0/gmls/AttributedGraphDataset:BlogCatalog_1.gml,False,False,True,True,False,3.1000000000000014,771,152.0\n",
    "datasets/GenCAT/AttributedGraphDataset:BlogCatalog_n_0_m_0/gmls/AttributedGraphDataset:BlogCatalog_2.gml,False,False,False,False,False,2.5600000000000014,910,399.0\n",
    "datasets/GenCAT/AttributedGraphDataset:BlogCatalog_n_0_m_0/gmls/AttributedGraphDataset:BlogCatalog_3.gml,False,False,False,False,False,2.410000000000001,845,427.0\n",
    "datasets/GenCAT/AttributedGraphDataset:BlogCatalog_n_0_m_0/gmls/AttributedGraphDataset:BlogCatalog_4.gml,False,False,True,True,False,3.690000000000002,898,184.0\n",
    "datasets/GenCAT/AttributedGraphDataset:BlogCatalog_n_0_m_0/gmls/AttributedGraphDataset:BlogCatalog_5.gml,False,False,False,False,False,2.7700000000000014,850,328.0\n",
    "datasets/GenCAT/AttributedGraphDataset:BlogCatalog_n_0_m_0/gmls/AttributedGraphDataset:BlogCatalog_complete.gml,False,False,False,False,False,1.4500000000000004,5196,5195.0\n",
    "\"\"\"\n",
    "    from io import StringIO\n",
    "    df_example = pd.read_csv(StringIO(csv_text), header=None)\n",
    "    # Suponha que você tenha outros DFs equivalentes (unatt, skymap, etc.). Aqui duplico só para demo:\n",
    "    dfs = [df_example, df_example.copy()]\n",
    "    labels = [\"GenCAT\", \"OutraFonte\"]\n",
    "\n",
    "    # Cria um radar por classe (0..5 e 'complete'), sobrepondo as duas fontes\n",
    "    plot_radars_per_class(\n",
    "        dfs=dfs,\n",
    "        labels=labels,\n",
    "        aggregate=\"mean\",          # se houver múltiplas linhas por (classe, fonte), faz a média\n",
    "        figsize=(6, 6),\n",
    "        save_dir=Path(\"radars_out\"),  # opcional: salva PNGs\n",
    "        show=True\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
